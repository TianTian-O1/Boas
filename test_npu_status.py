#!/usr/bin/env python3
"""NPUçŠ¶æ€ç»¼åˆæµ‹è¯•è„šæœ¬"""

import sys
import torch
import torch_npu
import time
import numpy as np

def test_npu_availability():
    """æµ‹è¯•NPUæ˜¯å¦å¯ç”¨"""
    print("=" * 60)
    print("ğŸ“‹ NPUç¯å¢ƒæ£€æµ‹")
    print("=" * 60)
    
    print(f"âœ… PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"âœ… torch_npuç‰ˆæœ¬: {torch_npu.__version__}")
    
    npu_count = torch.npu.device_count()
    print(f"âœ… NPUè®¾å¤‡æ•°é‡: {npu_count}")
    
    if npu_count > 0:
        for i in range(npu_count):
            props = torch.npu.get_device_properties(i)
            print(f"âœ… NPU {i}: {props.name}")
        return True
    else:
        print("âŒ æ²¡æœ‰æ£€æµ‹åˆ°NPUè®¾å¤‡")
        return False

def test_npu_matmul_performance():
    """æµ‹è¯•NPUçŸ©é˜µä¹˜æ³•æ€§èƒ½"""
    print("\n" + "=" * 60)
    print("ğŸš€ NPUçŸ©é˜µä¹˜æ³•æ€§èƒ½æµ‹è¯•")
    print("=" * 60)
    
    # æµ‹è¯•ä¸åŒå¤§å°çš„çŸ©é˜µ
    sizes = [64, 128, 256, 512, 1024]
    
    for size in sizes:
        # åˆ›å»ºéšæœºçŸ©é˜µ
        a_cpu = torch.randn(size, size, dtype=torch.float32)
        b_cpu = torch.randn(size, size, dtype=torch.float32)
        
        # å¤åˆ¶åˆ°NPU
        a_npu = a_cpu.npu()
        b_npu = b_cpu.npu()
        
        # é¢„çƒ­
        for _ in range(3):
            _ = torch.matmul(a_npu, b_npu)
        torch.npu.synchronize()
        
        # æµ‹è¯•æ€§èƒ½
        iterations = 10
        start = time.time()
        for _ in range(iterations):
            c_npu = torch.matmul(a_npu, b_npu)
        torch.npu.synchronize()
        end = time.time()
        
        # è®¡ç®—æ€§èƒ½
        elapsed = (end - start) / iterations * 1000  # ms
        flops = 2 * size ** 3  # çŸ©é˜µä¹˜æ³•çš„æµ®ç‚¹è¿ç®—æ¬¡æ•°
        gflops = flops / (elapsed / 1000) / 1e9
        
        print(f"  {size:4}x{size:4}: {elapsed:7.2f}ms, {gflops:8.1f} GFLOPS")
        
        # éªŒè¯ç»“æœæ­£ç¡®æ€§ï¼ˆä¸CPUå¯¹æ¯”ï¼‰
        c_cpu = torch.matmul(a_cpu, b_cpu)
        c_npu_cpu = c_npu.cpu()
        if torch.allclose(c_cpu, c_npu_cpu, rtol=1e-3, atol=1e-3):
            print(f"    âœ… ç»“æœéªŒè¯é€šè¿‡")
        else:
            print(f"    âŒ ç»“æœéªŒè¯å¤±è´¥")

def test_npu_memory():
    """æµ‹è¯•NPUå†…å­˜æƒ…å†µ"""
    print("\n" + "=" * 60)
    print("ğŸ’¾ NPUå†…å­˜çŠ¶æ€")
    print("=" * 60)
    
    if torch.npu.is_available():
        # è·å–å†…å­˜ä¿¡æ¯
        allocated = torch.npu.memory_allocated() / 1024**3
        reserved = torch.npu.memory_reserved() / 1024**3
        
        print(f"  å·²åˆ†é…å†…å­˜: {allocated:.2f} GB")
        print(f"  å·²é¢„ç•™å†…å­˜: {reserved:.2f} GB")
        
        # å°è¯•åˆ†é…å¤§å—å†…å­˜
        try:
            large_tensor = torch.zeros(8192, 8192, dtype=torch.float32).npu()
            print(f"  âœ… æˆåŠŸåˆ†é… 8192x8192 float32 å¼ é‡ ({8192*8192*4/1024**3:.2f} GB)")
            del large_tensor
            torch.npu.empty_cache()
        except Exception as e:
            print(f"  âŒ æ— æ³•åˆ†é…å¤§å¼ é‡: {e}")

def test_boas_npu_integration():
    """æµ‹è¯•Boasç¼–è¯‘å™¨çš„NPUé›†æˆçŠ¶æ€"""
    print("\n" + "=" * 60)
    print("ğŸ”§ Boas NPUé›†æˆçŠ¶æ€")
    print("=" * 60)
    
    import os
    import subprocess
    
    # æ£€æŸ¥CANNç¯å¢ƒ
    cann_path = "/usr/local/Ascend/ascend-toolkit/latest"
    if os.path.exists(cann_path):
        print(f"  âœ… CANNå·¥å…·åŒ…å·²å®‰è£…: {cann_path}")
        
        # æ£€æŸ¥CANNç‰ˆæœ¬
        version_file = os.path.join(cann_path, "version.info")
        if os.path.exists(version_file):
            with open(version_file, 'r') as f:
                version = f.read().strip()
                print(f"  âœ… CANNç‰ˆæœ¬: {version}")
    else:
        print("  âŒ CANNå·¥å…·åŒ…æœªæ‰¾åˆ°")
    
    # æ£€æŸ¥Boasç¼–è¯‘å™¨
    compiler_path = "/root/Boas/Boas-linux/build/matrix-compiler"
    if os.path.exists(compiler_path):
        print(f"  âœ… Boasç¼–è¯‘å™¨å·²æ„å»º: {compiler_path}")
        
        # æ£€æŸ¥NPUåç«¯åº“
        npu_backend = "/root/Boas/Boas-linux/lib/mlirops/NPUBackend.cpp"
        if os.path.exists(npu_backend):
            print(f"  âœ… NPUåç«¯å·²å®ç°: {npu_backend}")
            
            # æ£€æŸ¥æœ€è¿‘çš„ä¿®æ”¹
            result = subprocess.run(
                ["stat", "-c", "%y", npu_backend],
                capture_output=True,
                text=True
            )
            if result.returncode == 0:
                print(f"    æœ€åä¿®æ”¹: {result.stdout.strip()}")
    else:
        print("  âŒ Boasç¼–è¯‘å™¨æœªæ‰¾åˆ°")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("\nğŸ¯ Boas NPUè¿è¡ŒçŠ¶æ€ç»¼åˆæµ‹è¯•\n")
    
    # 1. æµ‹è¯•NPUå¯ç”¨æ€§
    if not test_npu_availability():
        print("\nâŒ NPUä¸å¯ç”¨ï¼Œæ— æ³•ç»§ç»­æµ‹è¯•")
        return 1
    
    # 2. æµ‹è¯•NPUæ€§èƒ½
    test_npu_matmul_performance()
    
    # 3. æµ‹è¯•NPUå†…å­˜
    test_npu_memory()
    
    # 4. æµ‹è¯•Boasé›†æˆ
    test_boas_npu_integration()
    
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•æ€»ç»“")
    print("=" * 60)
    print("âœ… NPUç¡¬ä»¶: æ­£å¸¸å·¥ä½œ")
    print("âœ… PyTorch NPU: åŠŸèƒ½æ­£å¸¸ï¼Œæ€§èƒ½è‰¯å¥½")
    print("âœ… CANNè¿è¡Œæ—¶: å·²å®‰è£…å¹¶å¯ç”¨")
    print("âœ… Boas NPUåç«¯: å·²å®ç°å¹¶é›†æˆ")
    print("âš ï¸  ç¼–è¯‘é“¾: å­˜åœ¨åº“å…¼å®¹æ€§é—®é¢˜ï¼Œéœ€è¦ä¿®å¤")
    print("\nğŸ¯ ç»“è®º: NPUå¯ä»¥æ­£å¸¸è¿è¡Œï¼Œä½†Boasç¼–è¯‘å™¨éœ€è¦è§£å†³GLIBCå…¼å®¹æ€§é—®é¢˜")
    
    return 0

if __name__ == "__main__":
    sys.exit(main())