#!/usr/bin/env python3
"""
ğŸ“Š Benchmarkæ€§èƒ½å¯¹æ¯”åˆ†æå™¨
æ·±åº¦åˆ†æBoas vs PyTorch vs CPUçš„æ€§èƒ½å·®è·å’Œä¼˜åŒ–æ½œåŠ›
"""

import json
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import os

class BenchmarkAnalyzer:
    def __init__(self):
        self.latest_results = None
        self.load_latest_results()
        
    def load_latest_results(self):
        """åŠ è½½æœ€æ–°çš„benchmarkç»“æœ"""
        results_dir = "results/optimization"
        if not os.path.exists(results_dir):
            print("âŒ æœªæ‰¾åˆ°benchmarkç»“æœç›®å½•")
            return
            
        # æŸ¥æ‰¾æœ€æ–°çš„benchmarkæ–‡ä»¶
        benchmark_files = [f for f in os.listdir(results_dir) if f.startswith('comprehensive_benchmark_')]
        if not benchmark_files:
            print("âŒ æœªæ‰¾åˆ°benchmarkç»“æœæ–‡ä»¶")
            return
            
        latest_file = max(benchmark_files)
        file_path = os.path.join(results_dir, latest_file)
        
        try:
            with open(file_path, 'r') as f:
                self.latest_results = json.load(f)
            print(f"âœ… åŠ è½½äº†æœ€æ–°benchmarkç»“æœ: {latest_file}")
        except Exception as e:
            print(f"âŒ åŠ è½½benchmarkç»“æœå¤±è´¥: {e}")
            
    def analyze_performance_scaling(self):
        """åˆ†ææ€§èƒ½æ‰©å±•æ€§"""
        print("\nğŸ“ˆ æ€§èƒ½æ‰©å±•æ€§åˆ†æ")
        print("=" * 50)
        
        if not self.latest_results:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„benchmarkæ•°æ®")
            return
            
        results = self.latest_results['results']
        
        # æå–ä¸åŒçŸ©é˜µå¤§å°çš„æ€§èƒ½æ•°æ®
        cpu_performance = {}
        npu_performance = {}
        
        for key, data in results.items():
            if 'cpu_' in key:
                size = key.replace('cpu_', '')
                cpu_performance[int(size)] = data['gflops']
            elif 'pytorch_npu_' in key:
                size = key.replace('pytorch_npu_', '')
                npu_performance[int(size)] = data['gflops']
                
        # åˆ†ææ‰©å±•æ€§
        print("ğŸ“Š CPUæ€§èƒ½æ‰©å±•:")
        prev_size = None
        for size in sorted(cpu_performance.keys()):
            perf = cpu_performance[size]
            if prev_size:
                scale_factor = size / prev_size
                perf_factor = perf / cpu_performance[prev_size]
                efficiency = perf_factor / (scale_factor ** 3)  # ç†è®ºä¸Šåº”è¯¥æ˜¯O(n^3)
                print(f"   {prev_size}x{prev_size} â†’ {size}x{size}: {perf:.1f} GFLOPS (æ•ˆç‡: {efficiency:.2f})")
            else:
                print(f"   {size}x{size}: {perf:.1f} GFLOPS")
            prev_size = size
            
        print("\nğŸ“Š NPUæ€§èƒ½æ‰©å±•:")
        prev_size = None
        for size in sorted(npu_performance.keys()):
            perf = npu_performance[size]
            if prev_size:
                scale_factor = size / prev_size
                perf_factor = perf / npu_performance[prev_size]
                efficiency = perf_factor / (scale_factor ** 3)
                print(f"   {prev_size}x{prev_size} â†’ {size}x{size}: {perf:.1f} GFLOPS (æ•ˆç‡: {efficiency:.2f})")
            else:
                print(f"   {size}x{size}: {perf:.1f} GFLOPS")
            prev_size = size
            
        return cpu_performance, npu_performance
        
    def analyze_npu_efficiency(self, npu_performance):
        """åˆ†æNPUæ•ˆç‡"""
        print(f"\nğŸš€ NPUæ•ˆç‡åˆ†æ")
        print("=" * 50)
        
        # æ˜‡è…¾910B2ç†è®ºå³°å€¼æ€§èƒ½
        theoretical_peak_fp32 = 50000  # GFLOPS (å‡è®¾å€¼)
        theoretical_peak_mixed = 100000  # GFLOPS (æ··åˆç²¾åº¦)
        
        print(f"ğŸ¯ ç†è®ºå³°å€¼æ€§èƒ½:")
        print(f"   FP32: {theoretical_peak_fp32:,} GFLOPS")
        print(f"   æ··åˆç²¾åº¦: {theoretical_peak_mixed:,} GFLOPS")
        
        print(f"\nğŸ“Š å®é™…æ€§èƒ½åˆ©ç”¨ç‡:")
        for size in sorted(npu_performance.keys()):
            actual_perf = npu_performance[size]
            utilization_fp32 = (actual_perf / theoretical_peak_fp32) * 100
            utilization_mixed = (actual_perf / theoretical_peak_mixed) * 100
            
            print(f"   {size}x{size}: {actual_perf:.1f} GFLOPS")
            print(f"      vs FP32å³°å€¼: {utilization_fp32:.2f}%")
            print(f"      vsæ··åˆç²¾åº¦å³°å€¼: {utilization_mixed:.2f}%")
            
        # åˆ†ææ€§èƒ½ç“¶é¢ˆ
        max_perf = max(npu_performance.values())
        max_size = max(npu_performance.keys())
        
        print(f"\nğŸ” æ€§èƒ½ç“¶é¢ˆåˆ†æ:")
        print(f"   æœ€å¤§æ€§èƒ½: {max_perf:.1f} GFLOPS ({max_size}x{max_size})")
        
        if max_perf < theoretical_peak_fp32 * 0.1:
            print(f"   ğŸ”´ ç“¶é¢ˆ: ä¸¥é‡çš„ç®—æ³•æˆ–å†…å­˜æ•ˆç‡é—®é¢˜")
        elif max_perf < theoretical_peak_fp32 * 0.3:
            print(f"   ğŸŸ¡ ç“¶é¢ˆ: ä¸­ç­‰çš„ä¼˜åŒ–ç©ºé—´ï¼Œå¯èƒ½æ˜¯å†…å­˜å¸¦å®½é™åˆ¶")
        else:
            print(f"   ğŸŸ¢ çŠ¶æ€: è‰¯å¥½çš„ç¡¬ä»¶åˆ©ç”¨ç‡")
            
    def project_boas_performance(self, npu_performance):
        """é¢„æµ‹Boasæ€§èƒ½æ½œåŠ›"""
        print(f"\nğŸ¯ Boasæ€§èƒ½æ½œåŠ›é¢„æµ‹")
        print("=" * 50)
        
        # è·å–Boaså½“å‰æ€§èƒ½
        boas_current = 0.000011  # GFLOPS (2x2)
        
        # åŸºäºPyTorchæ€§èƒ½é¢„æµ‹ä¸åŒä¼˜åŒ–é˜¶æ®µçš„Boasæ€§èƒ½
        optimization_stages = {
            "å½“å‰çŠ¶æ€": {
                "factor": 1.0,
                "description": "2x2çŸ©é˜µåŸºç¡€å®ç°"
            },
            "ä¿®å¤ç¼–è¯‘å™¨": {
                "factor": 6400,  # 16x16 vs 2x2
                "description": "æ”¯æŒ16x16çŸ©é˜µ"
            },
            "ç®—æ³•ä¼˜åŒ–": {
                "factor": 6400 * 16 * 2.5,  # 64x64 + ç®—æ³•ä¼˜åŒ–
                "description": "åˆ†å—ç®—æ³• + å¾ªç¯ä¼˜åŒ–"
            },
            "NPUå¹¶è¡Œ": {
                "factor": 6400 * 16 * 2.5 * 16,  # + NPUå¹¶è¡Œ
                "description": "å¤šAI Coreå¹¶è¡Œ"
            },
            "é«˜çº§ä¼˜åŒ–": {
                "factor": 6400 * 16 * 2.5 * 16 * 3,  # + é«˜çº§ä¼˜åŒ–
                "description": "æ··åˆç²¾åº¦ + kernelèåˆ"
            }
        }
        
        print("ğŸ“Š Boasæ€§èƒ½è·¯çº¿å›¾:")
        for stage, config in optimization_stages.items():
            projected_perf = boas_current * config['factor']
            
            # ä¸PyTorchæ€§èƒ½å¯¹æ¯”
            if projected_perf > 1000:  # åªå¯¹å¤§æ€§èƒ½å€¼è¿›è¡Œå¯¹æ¯”
                pytorch_512 = npu_performance.get(512, 0)
                vs_pytorch = (projected_perf / pytorch_512) * 100 if pytorch_512 > 0 else 0
                print(f"   {stage:12}: {projected_perf:8.1f} GFLOPS ({vs_pytorch:5.1f}% vs PyTorch)")
            else:
                print(f"   {stage:12}: {projected_perf:8.6f} GFLOPS")
            print(f"                 {config['description']}")
            
        # è®¡ç®—æœ€ç»ˆç›®æ ‡ä¸PyTorchçš„ç«äº‰åŠ›
        final_projected = boas_current * optimization_stages["é«˜çº§ä¼˜åŒ–"]["factor"]
        pytorch_best = max(npu_performance.values())
        
        print(f"\nğŸ† æœ€ç»ˆç›®æ ‡åˆ†æ:")
        print(f"   Boasç›®æ ‡æ€§èƒ½: {final_projected:.1f} GFLOPS")
        print(f"   PyTorchæœ€ä½³: {pytorch_best:.1f} GFLOPS")
        
        if final_projected >= pytorch_best * 1.2:
            print(f"   ğŸ¥‡ ç»“æœ: Boasæœ‰æœ›è¶…è¶ŠPyTorch 20%+")
        elif final_projected >= pytorch_best:
            print(f"   ğŸ¥ˆ ç»“æœ: Boasæœ‰æœ›è¾¾åˆ°PyTorchæ€§èƒ½æ°´å¹³")
        elif final_projected >= pytorch_best * 0.8:
            print(f"   ğŸ¥‰ ç»“æœ: Boasæœ‰æœ›è¾¾åˆ°PyTorch 80%æ€§èƒ½")
        else:
            print(f"   âš ï¸ ç»“æœ: éœ€è¦æ›´ç§¯æçš„ä¼˜åŒ–ç­–ç•¥")
            
        return optimization_stages, final_projected
        
    def analyze_optimization_priorities(self, cpu_performance, npu_performance):
        """åˆ†æä¼˜åŒ–ä¼˜å…ˆçº§"""
        print(f"\nğŸ¯ ä¼˜åŒ–ä¼˜å…ˆçº§åˆ†æ")
        print("=" * 50)
        
        # è®¡ç®—NPU vs CPUçš„åŠ é€Ÿæ¯”
        acceleration_ratios = {}
        for size in sorted(set(cpu_performance.keys()) & set(npu_performance.keys())):
            ratio = npu_performance[size] / cpu_performance[size]
            acceleration_ratios[size] = ratio
            
        print("ğŸ“Š NPUåŠ é€Ÿæ¯”åˆ†æ:")
        for size in sorted(acceleration_ratios.keys()):
            ratio = acceleration_ratios[size]
            print(f"   {size}x{size}: {ratio:.1f}x")
            
        # è¯†åˆ«æ€§èƒ½è·³è·ƒç‚¹
        print(f"\nğŸ” æ€§èƒ½è·³è·ƒç‚¹åˆ†æ:")
        npu_sizes = sorted(npu_performance.keys())
        for i in range(1, len(npu_sizes)):
            curr_size = npu_sizes[i]
            prev_size = npu_sizes[i-1]
            
            size_factor = curr_size / prev_size
            perf_factor = npu_performance[curr_size] / npu_performance[prev_size]
            
            if perf_factor > size_factor ** 2:  # è¶…çº¿æ€§åŠ é€Ÿ
                print(f"   ğŸš€ {prev_size}â†’{curr_size}: è¶…çº¿æ€§åŠ é€Ÿ ({perf_factor:.1f}x vs {size_factor**3:.1f}xæœŸæœ›)")
            elif perf_factor < size_factor:  # æ¬¡çº¿æ€§åŠ é€Ÿ
                print(f"   âš ï¸ {prev_size}â†’{curr_size}: æ¬¡çº¿æ€§åŠ é€Ÿ ({perf_factor:.1f}x vs {size_factor**3:.1f}xæœŸæœ›)")
                
        # ä¼˜åŒ–å»ºè®®
        max_ratio = max(acceleration_ratios.values())
        min_ratio = min(acceleration_ratios.values())
        
        print(f"\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
        if max_ratio > 8:
            print(f"   âœ… NPUå·²æ˜¾ç¤ºå¼ºåŠ²åŠ é€Ÿèƒ½åŠ› (æœ€é«˜{max_ratio:.1f}x)")
            print(f"   ğŸ¯ é‡ç‚¹: è®©Boasè¾¾åˆ°ç±»ä¼¼çš„NPUåˆ©ç”¨ç‡")
        else:
            print(f"   âš ï¸ NPUåŠ é€Ÿæ¯”æœ‰é™ (æœ€é«˜{max_ratio:.1f}x)")
            print(f"   ğŸ¯ é‡ç‚¹: åŒæ—¶ä¼˜åŒ–ç®—æ³•å’ŒNPUåˆ©ç”¨")
            
        if min_ratio < 3:
            print(f"   ğŸ“Š å°çŸ©é˜µæ€§èƒ½éœ€è¦ç‰¹åˆ«å…³æ³¨")
        if max_ratio / min_ratio > 3:
            print(f"   ğŸ“ˆ å¤§çŸ©é˜µæ˜¯NPUçš„å¼ºé¡¹ï¼Œä¼˜å…ˆæ”¯æŒå¤§è§„æ¨¡è®¡ç®—")
            
    def create_performance_comparison_chart(self, cpu_performance, npu_performance):
        """åˆ›å»ºæ€§èƒ½å¯¹æ¯”å›¾è¡¨"""
        print(f"\nğŸ“Š ç”Ÿæˆæ€§èƒ½å¯¹æ¯”å›¾è¡¨")
        print("=" * 50)
        
        # å‡†å¤‡æ•°æ®
        sizes = sorted(set(cpu_performance.keys()) & set(npu_performance.keys()))
        cpu_values = [cpu_performance[size] for size in sizes]
        npu_values = [npu_performance[size] for size in sizes]
        
        # BoasæŠ•å½±æ•°æ® (åŸºäºç†è®ºè®¡ç®—)
        boas_projected = []
        base_boas = 0.000011
        for size in sizes:
            # ç®€åŒ–çš„æŠ•å½±ï¼šåŸºäºçŸ©é˜µè§„æ¨¡å’Œé¢„æœŸä¼˜åŒ–æ•ˆæœ
            if size <= 64:
                factor = (size/2)**3 * 1000  # åŸºç¡€æ‰©å±•
            elif size <= 256:
                factor = (size/2)**3 * 5000  # ç®—æ³•ä¼˜åŒ–
            else:
                factor = (size/2)**3 * 20000  # å…¨é¢ä¼˜åŒ–
            projected = min(base_boas * factor, npu_performance[size] * 0.9)  # ä¸è¶…è¿‡PyTorchçš„90%
            boas_projected.append(projected)
            
        # åˆ›å»ºå›¾è¡¨æ•°æ®
        chart_data = {
            'matrix_sizes': [f"{size}x{size}" for size in sizes],
            'cpu_performance': cpu_values,
            'pytorch_npu_performance': npu_values,
            'boas_projected_performance': boas_projected,
            'acceleration_ratios': [npu_values[i]/cpu_values[i] for i in range(len(sizes))]
        }
        
        # ä¿å­˜å›¾è¡¨æ•°æ®
        os.makedirs('results/benchmarks', exist_ok=True)
        chart_file = f"results/benchmarks/performance_comparison_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        with open(chart_file, 'w') as f:
            json.dump(chart_data, f, indent=2)
            
        print(f"ğŸ“ å›¾è¡¨æ•°æ®å·²ä¿å­˜: {chart_file}")
        
        # æ‰“å°è¡¨æ ¼å½¢å¼çš„å¯¹æ¯”
        print(f"\nğŸ“‹ æ€§èƒ½å¯¹æ¯”è¡¨:")
        print(f"{'çŸ©é˜µå¤§å°':<10} {'CPU(GFLOPS)':<15} {'PyTorch+NPU':<15} {'Boasé¢„æœŸ':<15} {'NPUåŠ é€Ÿæ¯”':<10}")
        print("-" * 70)
        
        for i, size in enumerate(sizes):
            size_str = f"{size}x{size}"
            cpu_perf = cpu_values[i]
            npu_perf = npu_values[i]
            boas_perf = boas_projected[i]
            ratio = npu_perf / cpu_perf
            
            print(f"{size_str:<10} {cpu_perf:<15.1f} {npu_perf:<15.1f} {boas_perf:<15.1f} {ratio:<10.1f}")
            
        return chart_data
        
    def generate_comprehensive_report(self, cpu_performance, npu_performance, 
                                    optimization_stages, projected_performance):
        """ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š"""
        print(f"\nğŸ“‹ ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š")
        print("=" * 50)
        
        report = {
            'analysis_date': datetime.now().isoformat(),
            'performance_data': {
                'cpu_performance': cpu_performance,
                'npu_performance': npu_performance,
                'max_cpu_gflops': max(cpu_performance.values()),
                'max_npu_gflops': max(npu_performance.values()),
                'max_acceleration_ratio': max(npu_performance[s]/cpu_performance[s] for s in cpu_performance.keys() if s in npu_performance)
            },
            'boas_projections': {
                'optimization_stages': optimization_stages,
                'final_projected_gflops': projected_performance,
                'competitiveness_vs_pytorch': (projected_performance / max(npu_performance.values())) * 100
            },
            'key_insights': [
                f"PyTorch NPUåœ¨{max(npu_performance, key=npu_performance.get)}x{max(npu_performance, key=npu_performance.get)}çŸ©é˜µä¸Šè¾¾åˆ°å³°å€¼{max(npu_performance.values()):.1f} GFLOPS",
                f"NPUç›¸å¯¹CPUçš„æœ€å¤§åŠ é€Ÿæ¯”ä¸º{max(npu_performance[s]/cpu_performance[s] for s in cpu_performance.keys() if s in npu_performance):.1f}x",
                f"Boasæœ‰æ½œåŠ›è¾¾åˆ°{projected_performance:.1f} GFLOPS ({(projected_performance/max(npu_performance.values()))*100:.1f}% vs PyTorch)"
            ],
            'recommendations': [
                "ä¼˜å…ˆå®ç°å¤§çŸ©é˜µæ”¯æŒä»¥å‘æŒ¥NPUä¼˜åŠ¿",
                "é‡ç‚¹ä¼˜åŒ–å†…å­˜è®¿é—®æ¨¡å¼å’Œç®—æ³•æ•ˆç‡", 
                "é‡‡ç”¨æ··åˆç²¾åº¦å’Œå¹¶è¡Œç­–ç•¥",
                "å»ºç«‹æŒç»­æ€§èƒ½ç›‘æ§å’Œä¼˜åŒ–æœºåˆ¶"
            ]
        }
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = f"results/benchmarks/benchmark_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
            
        print(f"ğŸ“ ç»¼åˆåˆ†ææŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        
        # åˆ›å»ºMarkdownæ‘˜è¦
        md_file = report_file.replace('.json', '.md')
        with open(md_file, 'w') as f:
            f.write(f"""# ğŸ“Š Benchmarkæ€§èƒ½å¯¹æ¯”åˆ†ææŠ¥å‘Š

## ğŸ¯ åˆ†ææ‘˜è¦
- **åˆ†ææ—¥æœŸ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **CPUæœ€ä½³æ€§èƒ½**: {report['performance_data']['max_cpu_gflops']:.1f} GFLOPS
- **NPUæœ€ä½³æ€§èƒ½**: {report['performance_data']['max_npu_gflops']:.1f} GFLOPS
- **æœ€å¤§åŠ é€Ÿæ¯”**: {report['performance_data']['max_acceleration_ratio']:.1f}x

## ğŸš€ Boasæ€§èƒ½é¢„æµ‹
- **æœ€ç»ˆç›®æ ‡**: {report['boas_projections']['final_projected_gflops']:.1f} GFLOPS
- **ç«äº‰åŠ›**: {report['boas_projections']['competitiveness_vs_pytorch']:.1f}% vs PyTorch

## ğŸ’¡ å…³é”®æ´å¯Ÿ
""")
            for insight in report['key_insights']:
                f.write(f"- {insight}\n")
                
            f.write(f"\n## ğŸ“‹ ä¼˜åŒ–å»ºè®®\n")
            for rec in report['recommendations']:
                f.write(f"- {rec}\n")
                
        print(f"ğŸ“„ åˆ†ææ‘˜è¦å·²ä¿å­˜: {md_file}")
        
        return report

def main():
    """ä¸»åˆ†ææµç¨‹"""
    print("ğŸ“Š Benchmarkæ€§èƒ½å¯¹æ¯”åˆ†æå™¨")
    print("=" * 60)
    
    analyzer = BenchmarkAnalyzer()
    
    if not analyzer.latest_results:
        print("âŒ æ— æ³•ç»§ç»­åˆ†æï¼Œè¯·å…ˆè¿è¡Œbenchmarkæµ‹è¯•")
        return
        
    # 1. æ€§èƒ½æ‰©å±•æ€§åˆ†æ
    cpu_perf, npu_perf = analyzer.analyze_performance_scaling()
    
    # 2. NPUæ•ˆç‡åˆ†æ
    analyzer.analyze_npu_efficiency(npu_perf)
    
    # 3. Boasæ€§èƒ½é¢„æµ‹
    opt_stages, projected_perf = analyzer.project_boas_performance(npu_perf)
    
    # 4. ä¼˜åŒ–ä¼˜å…ˆçº§åˆ†æ
    analyzer.analyze_optimization_priorities(cpu_perf, npu_perf)
    
    # 5. æ€§èƒ½å¯¹æ¯”å›¾è¡¨
    chart_data = analyzer.create_performance_comparison_chart(cpu_perf, npu_perf)
    
    # 6. ç»¼åˆæŠ¥å‘Š
    report = analyzer.generate_comprehensive_report(cpu_perf, npu_perf, opt_stages, projected_perf)
    
    print(f"\nğŸ‰ Benchmarkåˆ†æå®Œæˆ!")
    print(f"ğŸ“Š å…³é”®å‘ç°: Boasæœ‰æ½œåŠ›è¾¾åˆ°{projected_perf:.1f} GFLOPS")
    print(f"ğŸ† ç«äº‰åŠ›: {(projected_perf/max(npu_perf.values()))*100:.1f}% vs PyTorchæœ€ä½³æ€§èƒ½")

if __name__ == "__main__":
    main()
