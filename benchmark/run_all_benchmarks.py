#!/usr/bin/env python3
"""
ğŸš€ è¿è¡Œæ‰€æœ‰æ€§èƒ½benchmarkå¹¶ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
"""

import os
import sys
import subprocess
import time
from pathlib import Path

def check_dependencies():
    """æ£€æŸ¥ä¾èµ–é¡¹"""
    print("ğŸ” Checking dependencies...")
    
    dependencies = {
        'numpy': 'NumPy for CPU baseline',
        'matplotlib': 'Matplotlib for visualization', 
        'seaborn': 'Seaborn for better plots'
    }
    
    missing = []
    
    for dep, desc in dependencies.items():
        try:
            __import__(dep)
            print(f"âœ… {dep} - {desc}")
        except ImportError:
            print(f"âŒ {dep} - {desc}")
            missing.append(dep)
    
    # æ£€æŸ¥torch_npu
    try:
        import torch
        import torch_npu
        print("âœ… torch_npu - PyTorch NPU support")
    except ImportError:
        print("âš ï¸ torch_npu - PyTorch NPU support (optional)")
    
    if missing:
        print(f"\nğŸ“¦ Installing missing dependencies: {', '.join(missing)}")
        subprocess.run([sys.executable, '-m', 'pip', 'install'] + missing)
    
    return True

def check_environment():
    """æ£€æŸ¥ç¯å¢ƒé…ç½®"""
    print("\nğŸ”§ Checking environment...")
    
    # æ£€æŸ¥CANNç¯å¢ƒ
    cann_path = "/usr/local/Ascend/ascend-toolkit/latest"
    if os.path.exists(cann_path):
        print(f"âœ… CANN toolkit found at {cann_path}")
    else:
        print(f"âŒ CANN toolkit not found at {cann_path}")
        return False
    
    # æ£€æŸ¥Boasç¼–è¯‘å™¨
    boas_root = "/root/Boas/Boas-linux"
    pipeline_exe = os.path.join(boas_root, "build", "test-full-pipeline")
    
    if os.path.exists(pipeline_exe):
        print(f"âœ… Boas compiler found at {pipeline_exe}")
    else:
        print(f"âŒ Boas compiler not found. Please compile first.")
        return False
    
    # æ£€æŸ¥NPUè®¾å¤‡
    npu_devices = [f for f in os.listdir("/dev") if f.startswith("davinci")]
    if npu_devices:
        print(f"âœ… NPU devices found: {', '.join(npu_devices)}")
    else:
        print("âš ï¸ No NPU devices found")
    
    return True

def run_benchmark_suite():
    """è¿è¡Œå®Œæ•´çš„benchmarkå¥—ä»¶"""
    print("\nğŸš€ Starting comprehensive benchmark suite...")
    print("=" * 80)
    
    benchmark_dir = Path(__file__).parent
    
    # 1. è¿è¡Œä¸»è¦benchmark
    print("ğŸ“Š Phase 1: Running main performance benchmark...")
    main_benchmark = benchmark_dir / "boas_benchmark.py"
    
    if main_benchmark.exists():
        result = subprocess.run([sys.executable, str(main_benchmark)], 
                              capture_output=True, text=True)
        if result.returncode == 0:
            print("âœ… Main benchmark completed successfully")
            print(result.stdout[-500:])  # æ˜¾ç¤ºæœ€å500ä¸ªå­—ç¬¦
        else:
            print("âŒ Main benchmark failed:")
            print(result.stderr[-500:])
            return False
    else:
        print(f"âŒ Main benchmark script not found: {main_benchmark}")
        return False
    
    # 2. è¿è¡ŒTriton-Ascendå¯¹æ¯” (å¯é€‰)
    print("\nâš¡ Phase 2: Running Triton-Ascend comparison...")
    triton_benchmark = benchmark_dir / "triton_ascend_benchmark.py"
    
    if triton_benchmark.exists():
        result = subprocess.run([sys.executable, str(triton_benchmark)], 
                              capture_output=True, text=True)
        if result.returncode == 0:
            print("âœ… Triton-Ascend benchmark completed")
        else:
            print("âš ï¸ Triton-Ascend benchmark failed (this is optional)")
            print(result.stderr[-300:])
    
    # 3. ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š
    print("\nğŸ“Š Phase 3: Generating visualization and reports...")
    visualizer = benchmark_dir / "performance_visualizer.py"
    
    if visualizer.exists():
        result = subprocess.run([sys.executable, str(visualizer)], 
                              capture_output=True, text=True)
        if result.returncode == 0:
            print("âœ… Visualization and reports generated")
            print(result.stdout)
        else:
            print("âŒ Visualization generation failed:")
            print(result.stderr[-300:])
    
    return True

def create_summary_report():
    """åˆ›å»ºæ€»ç»“æŠ¥å‘Š"""
    print("\nğŸ“ Creating summary report...")
    
    summary = f"""
# ğŸš€ Boas Language NPU Benchmark Summary

**Generated**: {time.strftime('%Y-%m-%d %H:%M:%S')}

## ğŸ¯ Benchmark Overview

This comprehensive benchmark compares the performance of:

1. **ğŸ¯ Boas+CANN** - Our MLIR-based NPU compiler
2. **ğŸ”¥ PyTorch+NPU** - Official torch_npu implementation  
3. **âš¡ Triton-Ascend** - Triton-based NPU kernels
4. **ğŸ’» CPU Baseline** - NumPy CPU implementation

## ğŸ“Š Test Matrix

| Scale | Matrix Size | Memory | Compute |
|-------|-------------|--------|---------|
| Small | 64Ã—64 | ~32KB | 262K FLOP |
| Medium | 256Ã—256 | ~512KB | 33M FLOP |
| Large | 1024Ã—1024 | ~8MB | 2.1B FLOP |
| XLarge | 2048Ã—2048 | ~32MB | 17B FLOP |

## ğŸ”§ Environment

- **Hardware**: æ˜‡è…¾910B2 NPU
- **Software**: CANN 8.1.RC1, LLVM 20
- **Boas Version**: Latest with CANN integration
- **Comparison**: PyTorch 2.0 + torch_npu

## ğŸ“ˆ Key Metrics

- **Execution Time** (milliseconds)
- **Throughput** (GFLOPS)  
- **Memory Bandwidth** (GB/s)
- **NPU Utilization** (%)
- **Compilation Time** (seconds)

## ğŸ† Expected Results

Based on our CANN integration:

- **Boas+CANN** should achieve competitive performance with PyTorch
- **Compilation time** advantage due to static optimization
- **Memory efficiency** from MLIR optimization passes
- **Scalability** benefits for large matrices

## ğŸ“‚ Generated Files

- `benchmark_results.json` - Raw performance data
- `performance_comparison_*.png` - Performance plots
- `speedup_analysis_*.png` - Speedup analysis
- `performance_report_*.md` - Detailed markdown report

## ğŸ” Analysis Focus

1. **Performance Parity**: How does Boas compare to PyTorch?
2. **Compilation Benefits**: Static vs dynamic optimization
3. **Scalability**: Performance across matrix sizes  
4. **NPU Utilization**: Hardware efficiency metrics
5. **Future Optimization**: Areas for improvement

---

ğŸ¯ **Goal**: Demonstrate that Boas language can achieve competitive NPU performance
through its MLIR-based CANN integration while providing better compile-time optimization.
"""
    
    with open("benchmark_summary.md", "w") as f:
        f.write(summary)
    
    print("âœ… Summary report saved to benchmark_summary.md")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ Boas Language NPU Comprehensive Benchmark Suite")
    print("=" * 80)
    print("ğŸ¯ Comparing: Boas+CANN vs PyTorch+NPU vs Triton vs CPU")
    print("=" * 80)
    
    try:
        # æ£€æŸ¥ä¾èµ–
        if not check_dependencies():
            print("âŒ Dependency check failed")
            sys.exit(1)
        
        # æ£€æŸ¥ç¯å¢ƒ
        if not check_environment():
            print("âŒ Environment check failed")
            sys.exit(1)
        
        # åˆ›å»ºæ€»ç»“æŠ¥å‘Š
        create_summary_report()
        
        # è¿è¡Œbenchmarkå¥—ä»¶
        success = run_benchmark_suite()
        
        if success:
            print("\n" + "=" * 80)
            print("ğŸ‰ BENCHMARK SUITE COMPLETED SUCCESSFULLY!")
            print("=" * 80)
            print("\nğŸ“‚ Generated files:")
            
            # åˆ—å‡ºç”Ÿæˆçš„æ–‡ä»¶
            generated_files = [
                "benchmark_results.json",
                "benchmark_summary.md"
            ]
            
            # æŸ¥æ‰¾æ—¶é—´æˆ³æ–‡ä»¶
            import glob
            generated_files.extend(glob.glob("performance_comparison_*.png"))
            generated_files.extend(glob.glob("speedup_analysis_*.png"))
            generated_files.extend(glob.glob("performance_report_*.md"))
            
            for file in generated_files:
                if os.path.exists(file):
                    print(f"   âœ… {file}")
                else:
                    print(f"   âŒ {file} (not generated)")
            
            print("\nğŸ” Check the generated reports for detailed performance analysis!")
            print("ğŸš€ Boas language NPU performance evaluation complete!")
            
        else:
            print("\nâŒ Benchmark suite failed")
            sys.exit(1)
            
    except KeyboardInterrupt:
        print("\nâš ï¸ Benchmark interrupted by user")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ Unexpected error: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
