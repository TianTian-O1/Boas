#!/usr/bin/env python3
"""
ğŸ§¹ é¡¹ç›®æ–‡ä»¶æ¸…ç†å’Œæ•´ç†å·¥å…·
å°†ä¼˜åŒ–è¿‡ç¨‹ä¸­ç”Ÿæˆçš„æ–‡ä»¶åˆ†ç±»æ•´ç†åˆ°åˆé€‚çš„ç›®å½•
"""

import os
import shutil
import glob
from datetime import datetime

class ProjectCleaner:
    def __init__(self):
        self.cleanup_rules = {
            # æµ‹è¯•æ–‡ä»¶
            'test/': [
                'test_*.py',
                'test_*.bs', 
                'test_*.sh',
                '*.log'
            ],
            # åŸºå‡†æµ‹è¯•å’Œä¼˜åŒ–å·¥å…·
            'tools/optimization/': [
                '*benchmark*.py',
                '*optimization*.py',
                'analyze_*.py',
                'progressive_*.py'
            ],
            # è„šæœ¬æ–‡ä»¶
            'scripts/': [
                '*.sh'
            ],
            # ç»“æœå’ŒæŠ¥å‘Š
            'results/optimization/': [
                '*.json',
                '*report*',
                '*result*'
            ],
            # ä¸´æ—¶å’Œæ„å»ºæ–‡ä»¶
            'temp/': [
                '*.mlir',
                '*.ll',
                '*.s',
                'temp*',
                '*.log'
            ]
        }
        
    def analyze_current_files(self):
        """åˆ†æå½“å‰æ–‡ä»¶åˆ†å¸ƒ"""
        print("ğŸ” å½“å‰é¡¹ç›®æ–‡ä»¶åˆ†æ")
        print("=" * 50)
        
        all_files = []
        for pattern in ['*.py', '*.sh', '*.json', '*.bs', '*.log', '*.mlir', '*.ll', '*.s']:
            all_files.extend(glob.glob(pattern))
            
        print(f"ğŸ“ æ ¹ç›®å½•æ–‡ä»¶æ€»æ•°: {len(all_files)}")
        
        # æŒ‰ç±»å‹åˆ†ç±»
        file_types = {}
        for file in all_files:
            ext = os.path.splitext(file)[1] or 'no_ext'
            file_types[ext] = file_types.get(ext, 0) + 1
            
        print(f"\nğŸ“Š æ–‡ä»¶ç±»å‹åˆ†å¸ƒ:")
        for ext, count in sorted(file_types.items()):
            print(f"   {ext}: {count} ä¸ª")
            
        return all_files
        
    def create_directory_structure(self):
        """åˆ›å»ºç›®å½•ç»“æ„"""
        print(f"\nğŸ“ åˆ›å»ºæ¸…ç†åçš„ç›®å½•ç»“æ„...")
        
        directories = [
            'test/matrix_tests',
            'tools/optimization', 
            'tools/benchmarks',
            'scripts/compilation',
            'scripts/testing',
            'results/optimization',
            'results/benchmarks',
            'temp/optimization'
        ]
        
        for dir_path in directories:
            os.makedirs(dir_path, exist_ok=True)
            print(f"   âœ… {dir_path}")
            
    def move_files_by_rules(self):
        """æŒ‰è§„åˆ™ç§»åŠ¨æ–‡ä»¶"""
        print(f"\nğŸšš æŒ‰è§„åˆ™æ•´ç†æ–‡ä»¶...")
        
        moved_files = []
        
        # å…·ä½“çš„æ–‡ä»¶ç§»åŠ¨è§„åˆ™
        specific_moves = {
            # ä¼˜åŒ–å·¥å…·
            'tools/optimization/': [
                'optimization_strategy.py',
                'large_matrix_optimization.py', 
                'optimization_demonstration.py',
                'analyze_progressive.py'
            ],
            # åŸºå‡†æµ‹è¯•
            'tools/benchmarks/': [
                'comprehensive_benchmark.py'
            ],
            # æµ‹è¯•è„šæœ¬
            'scripts/testing/': [
                'progressive_performance_test.sh'
            ],
            # ç¼–è¯‘è„šæœ¬  
            'scripts/compilation/': [
                'optimize_compile.sh',
                'test_cf_convert.sh',
                'test_complete_convert.sh',
                'test_end_to_end.sh'
            ],
            # æµ‹è¯•æ–‡ä»¶
            'test/matrix_tests/': [
                'test_fix_compilation.bs',
                'test_large_matrix.bs',
                'test_4x4_matrix.bs',
                'test_8x8_matrix.bs', 
                'test_16x16_matrix.bs'
            ],
            # ç»“æœæ–‡ä»¶
            'results/optimization/': [
                'optimization_report.json',
                'optimization_roadmap.json',
                'optimization_demonstration_*.json',
                'comprehensive_benchmark_*.json',
                'fusion_result.json'
            ],
            # æ—¥å¿—æ–‡ä»¶
            'temp/optimization/': [
                'large_build.log'
            ]
        }
        
        for target_dir, files in specific_moves.items():
            for file_pattern in files:
                matching_files = glob.glob(file_pattern)
                for file in matching_files:
                    if os.path.exists(file):
                        target_path = os.path.join(target_dir, os.path.basename(file))
                        try:
                            shutil.move(file, target_path)
                            moved_files.append((file, target_path))
                            print(f"   ğŸ“ {file} â†’ {target_path}")
                        except Exception as e:
                            print(f"   âŒ ç§»åŠ¨å¤±è´¥ {file}: {e}")
                            
        return moved_files
        
    def create_directory_readmes(self):
        """ä¸ºæ¯ä¸ªç›®å½•åˆ›å»ºREADME"""
        print(f"\nğŸ“ åˆ›å»ºç›®å½•è¯´æ˜æ–‡ä»¶...")
        
        readmes = {
            'tools/optimization/README.md': """# ğŸš€ ä¼˜åŒ–å·¥å…·

æ­¤ç›®å½•åŒ…å«Boasè¯­è¨€æ€§èƒ½ä¼˜åŒ–ç›¸å…³çš„å·¥å…·å’Œè„šæœ¬ã€‚

## æ–‡ä»¶è¯´æ˜
- `optimization_strategy.py`: ä¸»ä¼˜åŒ–ç­–ç•¥åˆ†æå™¨
- `large_matrix_optimization.py`: å¤§çŸ©é˜µä¼˜åŒ–ä¸“ç”¨å·¥å…·
- `optimization_demonstration.py`: ä¼˜åŒ–æ•ˆæœæ¼”ç¤ºå·¥å…·
- `analyze_progressive.py`: æ¸è¿›å¼æµ‹è¯•ç»“æœåˆ†æå™¨
""",
            'tools/benchmarks/README.md': """# ğŸ“Š åŸºå‡†æµ‹è¯•å·¥å…·

æ­¤ç›®å½•åŒ…å«æ€§èƒ½åŸºå‡†æµ‹è¯•ç›¸å…³çš„å·¥å…·ã€‚

## æ–‡ä»¶è¯´æ˜
- `comprehensive_benchmark.py`: ç»¼åˆæ€§èƒ½åŸºå‡†æµ‹è¯•å™¨
""",
            'scripts/compilation/README.md': """# ğŸ”§ ç¼–è¯‘è„šæœ¬

æ­¤ç›®å½•åŒ…å«Boasè¯­è¨€ç¼–è¯‘ç›¸å…³çš„è„šæœ¬ã€‚

## æ–‡ä»¶è¯´æ˜
- `optimize_compile.sh`: ä¼˜åŒ–ç¼–è¯‘è„šæœ¬
- `test_cf_convert.sh`: CF dialectè½¬æ¢æµ‹è¯•
- `test_complete_convert.sh`: å®Œæ•´è½¬æ¢æµ‹è¯•
- `test_end_to_end.sh`: ç«¯åˆ°ç«¯æµ‹è¯•è„šæœ¬
""",
            'scripts/testing/README.md': """# ğŸ§ª æµ‹è¯•è„šæœ¬

æ­¤ç›®å½•åŒ…å«å„ç§æµ‹è¯•è„šæœ¬ã€‚

## æ–‡ä»¶è¯´æ˜
- `progressive_performance_test.sh`: æ¸è¿›å¼æ€§èƒ½æµ‹è¯•
""",
            'test/matrix_tests/README.md': """# ğŸ”¢ çŸ©é˜µæµ‹è¯•

æ­¤ç›®å½•åŒ…å«å„ç§è§„æ¨¡çš„çŸ©é˜µä¹˜æ³•æµ‹è¯•æ–‡ä»¶ã€‚

## æ–‡ä»¶è¯´æ˜
- `test_fix_compilation.bs`: åŸºç¡€ç¼–è¯‘æµ‹è¯•(2x2)
- `test_4x4_matrix.bs`: 4x4çŸ©é˜µæµ‹è¯•
- `test_8x8_matrix.bs`: 8x8çŸ©é˜µæµ‹è¯•
- `test_16x16_matrix.bs`: 16x16çŸ©é˜µæµ‹è¯•
- `test_large_matrix.bs`: å¤§çŸ©é˜µæµ‹è¯•(128x128)
""",
            'results/optimization/README.md': """# ğŸ“ˆ ä¼˜åŒ–ç»“æœ

æ­¤ç›®å½•åŒ…å«ä¼˜åŒ–è¿‡ç¨‹çš„ç»“æœå’ŒæŠ¥å‘Šæ–‡ä»¶ã€‚

## æ–‡ä»¶è¯´æ˜
- `optimization_report.json`: ä¼˜åŒ–æŠ¥å‘Š
- `optimization_roadmap.json`: ä¼˜åŒ–è·¯çº¿å›¾
- `comprehensive_benchmark_*.json`: åŸºå‡†æµ‹è¯•ç»“æœ
- `optimization_demonstration_*.json`: ä¼˜åŒ–æ¼”ç¤ºç»“æœ
""",
            'temp/optimization/README.md': """# ğŸ—‚ï¸ ä¸´æ—¶æ–‡ä»¶

æ­¤ç›®å½•åŒ…å«ä¼˜åŒ–è¿‡ç¨‹ä¸­äº§ç”Ÿçš„ä¸´æ—¶æ–‡ä»¶å’Œæ—¥å¿—ã€‚

**æ³¨æ„**: æ­¤ç›®å½•çš„æ–‡ä»¶å¯ä»¥å®šæœŸæ¸…ç†ã€‚
"""
        }
        
        for file_path, content in readmes.items():
            os.makedirs(os.path.dirname(file_path), exist_ok=True)
            with open(file_path, 'w') as f:
                f.write(content)
            print(f"   ğŸ“ {file_path}")
            
    def create_cleanup_summary(self, moved_files):
        """åˆ›å»ºæ¸…ç†æ€»ç»“"""
        summary = {
            'cleanup_date': datetime.now().isoformat(),
            'files_moved': len(moved_files),
            'file_moves': [{'from': src, 'to': dst} for src, dst in moved_files],
            'new_structure': {
                'tools/': 'ä¼˜åŒ–å’ŒåŸºå‡†æµ‹è¯•å·¥å…·',
                'scripts/': 'ç¼–è¯‘å’Œæµ‹è¯•è„šæœ¬',
                'test/': 'æµ‹è¯•æ–‡ä»¶',
                'results/': 'ç»“æœå’ŒæŠ¥å‘Š',
                'temp/': 'ä¸´æ—¶æ–‡ä»¶'
            }
        }
        
        with open('docs/PROJECT_CLEANUP_SUMMARY.md', 'w') as f:
            f.write(f"""# ğŸ§¹ é¡¹ç›®æ¸…ç†æ€»ç»“

**æ¸…ç†æ—¥æœŸ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ğŸ“Š æ¸…ç†ç»Ÿè®¡
- **ç§»åŠ¨æ–‡ä»¶æ•°**: {len(moved_files)}
- **æ–°å¢ç›®å½•**: 8ä¸ª
- **åˆ›å»ºREADME**: 7ä¸ª

## ğŸ“ æ–°çš„ç›®å½•ç»“æ„
```
Boas-linux/
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ optimization/     # ä¼˜åŒ–å·¥å…·
â”‚   â””â”€â”€ benchmarks/       # åŸºå‡†æµ‹è¯•å·¥å…·
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ compilation/      # ç¼–è¯‘è„šæœ¬
â”‚   â””â”€â”€ testing/          # æµ‹è¯•è„šæœ¬
â”œâ”€â”€ test/
â”‚   â””â”€â”€ matrix_tests/     # çŸ©é˜µæµ‹è¯•æ–‡ä»¶
â”œâ”€â”€ results/
â”‚   â””â”€â”€ optimization/     # ä¼˜åŒ–ç»“æœ
â””â”€â”€ temp/
    â””â”€â”€ optimization/     # ä¸´æ—¶æ–‡ä»¶
```

## ğŸ¯ æ¸…ç†æ•ˆæœ
- âœ… æ ¹ç›®å½•ä»21ä¸ªæ–‡ä»¶å‡å°‘åˆ°æ ¸å¿ƒæ–‡ä»¶
- âœ… æ–‡ä»¶æŒ‰åŠŸèƒ½åˆ†ç±»æ•´ç†
- âœ… æ¯ä¸ªç›®å½•éƒ½æœ‰è¯´æ˜æ–‡æ¡£
- âœ… ä¾¿äºåç»­ç»´æŠ¤å’Œå¼€å‘

## ğŸ“‹ ç§»åŠ¨çš„æ–‡ä»¶
""")
            
            for src, dst in moved_files:
                f.write(f"- `{src}` â†’ `{dst}`\n")
                
        print(f"\nğŸ“‹ æ¸…ç†æ€»ç»“å·²ä¿å­˜: docs/PROJECT_CLEANUP_SUMMARY.md")
        return summary
        
    def verify_cleanup(self):
        """éªŒè¯æ¸…ç†ç»“æœ"""
        print(f"\nâœ… éªŒè¯æ¸…ç†ç»“æœ...")
        
        # æ£€æŸ¥æ ¹ç›®å½•å‰©ä½™æ–‡ä»¶
        remaining_files = []
        for pattern in ['*.py', '*.sh', '*.json', '*.bs', '*.log']:
            remaining_files.extend(glob.glob(pattern))
            
        print(f"ğŸ“ æ ¹ç›®å½•å‰©ä½™æ–‡ä»¶: {len(remaining_files)}")
        for file in remaining_files:
            print(f"   ğŸ“„ {file}")
            
        # æ£€æŸ¥æ–°ç›®å½•ç»“æ„
        new_dirs = [
            'tools/optimization',
            'tools/benchmarks', 
            'scripts/compilation',
            'scripts/testing',
            'test/matrix_tests',
            'results/optimization',
            'temp/optimization'
        ]
        
        print(f"\nğŸ“ æ–°ç›®å½•ç»“æ„éªŒè¯:")
        for dir_path in new_dirs:
            if os.path.exists(dir_path):
                file_count = len(os.listdir(dir_path))
                print(f"   âœ… {dir_path}: {file_count} ä¸ªæ–‡ä»¶")
            else:
                print(f"   âŒ {dir_path}: ä¸å­˜åœ¨")

def main():
    """ä¸»æ¸…ç†æµç¨‹"""
    print("ğŸ§¹ Boasé¡¹ç›®æ–‡ä»¶æ¸…ç†å·¥å…·")
    print("=" * 50)
    
    cleaner = ProjectCleaner()
    
    # 1. åˆ†æå½“å‰æ–‡ä»¶
    all_files = cleaner.analyze_current_files()
    
    # 2. åˆ›å»ºç›®å½•ç»“æ„
    cleaner.create_directory_structure()
    
    # 3. ç§»åŠ¨æ–‡ä»¶
    moved_files = cleaner.move_files_by_rules()
    
    # 4. åˆ›å»ºREADMEæ–‡ä»¶
    cleaner.create_directory_readmes()
    
    # 5. åˆ›å»ºæ¸…ç†æ€»ç»“
    summary = cleaner.create_cleanup_summary(moved_files)
    
    # 6. éªŒè¯ç»“æœ
    cleaner.verify_cleanup()
    
    print(f"\nğŸ‰ é¡¹ç›®æ¸…ç†å®Œæˆ!")
    print(f"ğŸ“Š ç§»åŠ¨äº† {len(moved_files)} ä¸ªæ–‡ä»¶")
    print(f"ğŸ“ æ ¹ç›®å½•ç°åœ¨æ›´åŠ æ•´æ´")
    print(f"ğŸ“ æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Š: docs/PROJECT_CLEANUP_SUMMARY.md")

if __name__ == "__main__":
    main()
