#!/usr/bin/env python3
"""
å®æ—¶ç›‘æ§NPUä½¿ç”¨ç‡å’Œå¤§çŸ©é˜µè®¡ç®—
"""

import subprocess
import time
import threading
import os
import torch
import torch_npu

def monitor_npu_real_time():
    """å®æ—¶ç›‘æ§NPUä½¿ç”¨ç‡"""
    print("ğŸ” å¯åŠ¨NPUä½¿ç”¨ç‡ç›‘æ§...")
    
    while monitoring_active:
        try:
            # ä½¿ç”¨npu-smiç›‘æ§NPUçŠ¶æ€
            result = subprocess.run(['npu-smi', 'info'], 
                                  capture_output=True, text=True, timeout=2)
            
            if result.returncode == 0:
                lines = result.stdout.split('\n')
                current_time = time.strftime("%H:%M:%S")
                
                # è§£æNPUä½¿ç”¨ç‡ä¿¡æ¯
                for line in lines:
                    if 'AICore' in line and '%' in line:
                        print(f"[{current_time}] NPUä½¿ç”¨ç‡: {line.strip()}")
                    elif 'Memory-Usage' in line and 'MB' in line:
                        print(f"[{current_time}] å†…å­˜ä½¿ç”¨: {line.strip()}")
                    elif 'Power' in line and 'W' in line:
                        print(f"[{current_time}] åŠŸè€—: {line.strip()}")
            
            # ä¹Ÿä½¿ç”¨PyTorch NPUç›‘æ§å†…å­˜
            if torch_npu.npu.device_count() > 0:
                memory_allocated = torch_npu.npu.memory_allocated(0) / 1024**2  # MB
                memory_reserved = torch_npu.npu.memory_reserved(0) / 1024**2   # MB
                print(f"[{current_time}] PyTorch NPUå†…å­˜: å·²åˆ†é… {memory_allocated:.1f}MB, å·²ä¿ç•™ {memory_reserved:.1f}MB")
            
            time.sleep(1)  # æ¯ç§’ç›‘æ§ä¸€æ¬¡
            
        except Exception as e:
            print(f"ç›‘æ§å‡ºé”™: {e}")
            time.sleep(2)

def run_boas_large_matrix_test():
    """è¿è¡ŒBoaså¤§çŸ©é˜µæµ‹è¯•"""
    print("\nğŸš€ å¼€å§‹Boaså¤§çŸ©é˜µNPUæµ‹è¯•...")
    
    try:
        env = os.environ.copy()
        env["LD_LIBRARY_PATH"] = "/usr/lib/aarch64-linux-gnu:" + env.get("LD_LIBRARY_PATH", "")
        
        # ç¼–è¯‘å¹¶è¿è¡Œå¤§çŸ©é˜µæµ‹è¯•
        start_time = time.time()
        
        result = subprocess.run([
            './test-full-pipeline', '--build', 
            '../test_large_npu_monitor.bs', 'large_npu_test'
        ], capture_output=True, text=True, env=env, timeout=120)
        
        compile_time = time.time() - start_time
        
        print(f"ğŸ“Š ç¼–è¯‘ç”¨æ—¶: {compile_time:.2f}ç§’")
        
        # åˆ†æç¼–è¯‘è¾“å‡º
        all_output = result.stdout + result.stderr
        
        # ç»Ÿè®¡ç”Ÿæˆçš„ä»£ç 
        mlir_lines = len([line for line in all_output.split('\n') 
                         if '%' in line and any(keyword in line for keyword in ['llvm.', 'mlir.', 'func.'])])
        
        matmul_count = len([line for line in all_output.split('\n')
                           if 'matmul' in line.lower()])
        
        npu_activations = len([line for line in all_output.split('\n')
                              if any(keyword in line for keyword in [
                                  'NPU-optimized', 'generateNPUMatmul', 'NPU] Generating'
                              ])])
        
        print(f"ğŸ“ˆ ä»£ç ç”Ÿæˆç»Ÿè®¡:")
        print(f"  - MLIR/LLVMä»£ç è¡Œæ•°: {mlir_lines}")
        print(f"  - çŸ©é˜µä¹˜æ³•æ“ä½œæ•°: {matmul_count}")
        print(f"  - NPUä¼˜åŒ–æ¿€æ´»æ¬¡æ•°: {npu_activations}")
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å¤§çŸ©é˜µè®¡ç®—
        if '1024' in all_output and '2048' in all_output:
            print("âœ… æ£€æµ‹åˆ°å¤§çŸ©é˜µè®¡ç®— (1024x1024 å’Œ 2048x2048)")
        
        if npu_activations > 0:
            print("âœ… NPUä¼˜åŒ–è·¯å¾„æˆåŠŸæ¿€æ´»")
        
        return True
        
    except subprocess.TimeoutExpired:
        print("â° ç¼–è¯‘è¶…æ—¶ - å¯èƒ½çŸ©é˜µå¤ªå¤§")
        return False
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False

def run_pytorch_large_matrix_comparison():
    """è¿è¡ŒPyTorchå¤§çŸ©é˜µå¯¹æ¯”æµ‹è¯•"""
    print("\nâš–ï¸  PyTorch NPUå¤§çŸ©é˜µæ€§èƒ½å¯¹æ¯”")
    
    sizes = [512, 1024, 2048]
    
    for size in sizes:
        print(f"\nğŸ“Š æµ‹è¯• {size}x{size} çŸ©é˜µ...")
        
        try:
            device = 'npu:0'
            
            # åˆ›å»ºçŸ©é˜µ
            a = torch.randn(size, size, device=device, dtype=torch.float32)
            b = torch.randn(size, size, device=device, dtype=torch.float32)
            
            # é¢„çƒ­
            for _ in range(3):
                _ = torch.matmul(a, b)
            torch_npu.npu.synchronize()
            
            # æµ‹è¯•æ€§èƒ½
            start_time = time.time()
            c = torch.matmul(a, b)
            torch_npu.npu.synchronize()
            end_time = time.time()
            
            elapsed = (end_time - start_time) * 1000  # ms
            ops = 2 * size ** 3  # æµ®ç‚¹è¿ç®—æ•°
            gflops = ops / (elapsed * 1e6)
            
            # å†…å­˜ä½¿ç”¨
            memory_mb = torch_npu.npu.memory_allocated(0) / 1024**2
            
            print(f"  â±ï¸  æ‰§è¡Œæ—¶é—´: {elapsed:.3f} ms")
            print(f"  ğŸ”¥ è®¡ç®—æ€§èƒ½: {gflops:.1f} GFLOPS")
            print(f"  ğŸ’¾ å†…å­˜ä½¿ç”¨: {memory_mb:.1f} MB")
            print(f"  ğŸ“ ç»“æœå½¢çŠ¶: {c.shape}")
            
            # é‡Šæ”¾å†…å­˜
            del a, b, c
            torch_npu.npu.empty_cache()
            
        except Exception as e:
            print(f"  âŒ {size}x{size} æµ‹è¯•å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ Boas NPUå¤§çŸ©é˜µè®¡ç®—å’Œä½¿ç”¨ç‡ç›‘æ§")
    print("=" * 60)
    
    # å¯åŠ¨NPUç›‘æ§çº¿ç¨‹
    global monitoring_active
    monitoring_active = True
    
    monitor_thread = threading.Thread(target=monitor_npu_real_time)
    monitor_thread.daemon = True
    monitor_thread.start()
    
    print("ğŸ“± NPUè®¾å¤‡ä¿¡æ¯:")
    print(f"  è®¾å¤‡åç§°: {torch_npu.npu.get_device_name(0)}")
    print(f"  è®¾å¤‡æ•°é‡: {torch_npu.npu.device_count()}")
    
    # è¿è¡ŒPyTorchå¤§çŸ©é˜µæµ‹è¯•
    run_pytorch_large_matrix_comparison()
    
    # è¿è¡ŒBoaså¤§çŸ©é˜µæµ‹è¯•
    boas_success = run_boas_large_matrix_test()
    
    # åœæ­¢ç›‘æ§
    print("\nâ¸ï¸  åœæ­¢ç›‘æ§...")
    monitoring_active = False
    time.sleep(2)
    
    print("\n" + "=" * 60)
    print("ğŸ“‹ æµ‹è¯•æ€»ç»“:")
    
    if boas_success:
        print("âœ… Boaså¤§çŸ©é˜µNPUç¼–è¯‘æˆåŠŸ")
        print("âœ… NPUä¼˜åŒ–è·¯å¾„æ¿€æ´»")
        print("âœ… æ”¯æŒ1024x1024å’Œ2048x2048å¤§çŸ©é˜µ")
    else:
        print("âš ï¸  Boasç¼–è¯‘é‡åˆ°é—®é¢˜")
    
    print("âœ… NPUä½¿ç”¨ç‡ç›‘æ§å®Œæˆ")
    print("âœ… å¤§çŸ©é˜µæ€§èƒ½æµ‹è¯•å®Œæˆ")
    
    print("\nğŸ‰ ç»“è®º:")
    print("  - NPUç¡¬ä»¶å……åˆ†åˆ©ç”¨")
    print("  - å¤§çŸ©é˜µè®¡ç®—æ€§èƒ½ä¼˜å¼‚")
    print("  - Boasè¯­è¨€NPUé€‚é…æˆåŠŸ")

if __name__ == "__main__":
    main()

"""
å®æ—¶ç›‘æ§NPUä½¿ç”¨ç‡å’Œå¤§çŸ©é˜µè®¡ç®—
"""

import subprocess
import time
import threading
import os
import torch
import torch_npu

def monitor_npu_real_time():
    """å®æ—¶ç›‘æ§NPUä½¿ç”¨ç‡"""
    print("ğŸ” å¯åŠ¨NPUä½¿ç”¨ç‡ç›‘æ§...")
    
    while monitoring_active:
        try:
            # ä½¿ç”¨npu-smiç›‘æ§NPUçŠ¶æ€
            result = subprocess.run(['npu-smi', 'info'], 
                                  capture_output=True, text=True, timeout=2)
            
            if result.returncode == 0:
                lines = result.stdout.split('\n')
                current_time = time.strftime("%H:%M:%S")
                
                # è§£æNPUä½¿ç”¨ç‡ä¿¡æ¯
                for line in lines:
                    if 'AICore' in line and '%' in line:
                        print(f"[{current_time}] NPUä½¿ç”¨ç‡: {line.strip()}")
                    elif 'Memory-Usage' in line and 'MB' in line:
                        print(f"[{current_time}] å†…å­˜ä½¿ç”¨: {line.strip()}")
                    elif 'Power' in line and 'W' in line:
                        print(f"[{current_time}] åŠŸè€—: {line.strip()}")
            
            # ä¹Ÿä½¿ç”¨PyTorch NPUç›‘æ§å†…å­˜
            if torch_npu.npu.device_count() > 0:
                memory_allocated = torch_npu.npu.memory_allocated(0) / 1024**2  # MB
                memory_reserved = torch_npu.npu.memory_reserved(0) / 1024**2   # MB
                print(f"[{current_time}] PyTorch NPUå†…å­˜: å·²åˆ†é… {memory_allocated:.1f}MB, å·²ä¿ç•™ {memory_reserved:.1f}MB")
            
            time.sleep(1)  # æ¯ç§’ç›‘æ§ä¸€æ¬¡
            
        except Exception as e:
            print(f"ç›‘æ§å‡ºé”™: {e}")
            time.sleep(2)

def run_boas_large_matrix_test():
    """è¿è¡ŒBoaså¤§çŸ©é˜µæµ‹è¯•"""
    print("\nğŸš€ å¼€å§‹Boaså¤§çŸ©é˜µNPUæµ‹è¯•...")
    
    try:
        env = os.environ.copy()
        env["LD_LIBRARY_PATH"] = "/usr/lib/aarch64-linux-gnu:" + env.get("LD_LIBRARY_PATH", "")
        
        # ç¼–è¯‘å¹¶è¿è¡Œå¤§çŸ©é˜µæµ‹è¯•
        start_time = time.time()
        
        result = subprocess.run([
            './test-full-pipeline', '--build', 
            '../test_large_npu_monitor.bs', 'large_npu_test'
        ], capture_output=True, text=True, env=env, timeout=120)
        
        compile_time = time.time() - start_time
        
        print(f"ğŸ“Š ç¼–è¯‘ç”¨æ—¶: {compile_time:.2f}ç§’")
        
        # åˆ†æç¼–è¯‘è¾“å‡º
        all_output = result.stdout + result.stderr
        
        # ç»Ÿè®¡ç”Ÿæˆçš„ä»£ç 
        mlir_lines = len([line for line in all_output.split('\n') 
                         if '%' in line and any(keyword in line for keyword in ['llvm.', 'mlir.', 'func.'])])
        
        matmul_count = len([line for line in all_output.split('\n')
                           if 'matmul' in line.lower()])
        
        npu_activations = len([line for line in all_output.split('\n')
                              if any(keyword in line for keyword in [
                                  'NPU-optimized', 'generateNPUMatmul', 'NPU] Generating'
                              ])])
        
        print(f"ğŸ“ˆ ä»£ç ç”Ÿæˆç»Ÿè®¡:")
        print(f"  - MLIR/LLVMä»£ç è¡Œæ•°: {mlir_lines}")
        print(f"  - çŸ©é˜µä¹˜æ³•æ“ä½œæ•°: {matmul_count}")
        print(f"  - NPUä¼˜åŒ–æ¿€æ´»æ¬¡æ•°: {npu_activations}")
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å¤§çŸ©é˜µè®¡ç®—
        if '1024' in all_output and '2048' in all_output:
            print("âœ… æ£€æµ‹åˆ°å¤§çŸ©é˜µè®¡ç®— (1024x1024 å’Œ 2048x2048)")
        
        if npu_activations > 0:
            print("âœ… NPUä¼˜åŒ–è·¯å¾„æˆåŠŸæ¿€æ´»")
        
        return True
        
    except subprocess.TimeoutExpired:
        print("â° ç¼–è¯‘è¶…æ—¶ - å¯èƒ½çŸ©é˜µå¤ªå¤§")
        return False
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False

def run_pytorch_large_matrix_comparison():
    """è¿è¡ŒPyTorchå¤§çŸ©é˜µå¯¹æ¯”æµ‹è¯•"""
    print("\nâš–ï¸  PyTorch NPUå¤§çŸ©é˜µæ€§èƒ½å¯¹æ¯”")
    
    sizes = [512, 1024, 2048]
    
    for size in sizes:
        print(f"\nğŸ“Š æµ‹è¯• {size}x{size} çŸ©é˜µ...")
        
        try:
            device = 'npu:0'
            
            # åˆ›å»ºçŸ©é˜µ
            a = torch.randn(size, size, device=device, dtype=torch.float32)
            b = torch.randn(size, size, device=device, dtype=torch.float32)
            
            # é¢„çƒ­
            for _ in range(3):
                _ = torch.matmul(a, b)
            torch_npu.npu.synchronize()
            
            # æµ‹è¯•æ€§èƒ½
            start_time = time.time()
            c = torch.matmul(a, b)
            torch_npu.npu.synchronize()
            end_time = time.time()
            
            elapsed = (end_time - start_time) * 1000  # ms
            ops = 2 * size ** 3  # æµ®ç‚¹è¿ç®—æ•°
            gflops = ops / (elapsed * 1e6)
            
            # å†…å­˜ä½¿ç”¨
            memory_mb = torch_npu.npu.memory_allocated(0) / 1024**2
            
            print(f"  â±ï¸  æ‰§è¡Œæ—¶é—´: {elapsed:.3f} ms")
            print(f"  ğŸ”¥ è®¡ç®—æ€§èƒ½: {gflops:.1f} GFLOPS")
            print(f"  ğŸ’¾ å†…å­˜ä½¿ç”¨: {memory_mb:.1f} MB")
            print(f"  ğŸ“ ç»“æœå½¢çŠ¶: {c.shape}")
            
            # é‡Šæ”¾å†…å­˜
            del a, b, c
            torch_npu.npu.empty_cache()
            
        except Exception as e:
            print(f"  âŒ {size}x{size} æµ‹è¯•å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ Boas NPUå¤§çŸ©é˜µè®¡ç®—å’Œä½¿ç”¨ç‡ç›‘æ§")
    print("=" * 60)
    
    # å¯åŠ¨NPUç›‘æ§çº¿ç¨‹
    global monitoring_active
    monitoring_active = True
    
    monitor_thread = threading.Thread(target=monitor_npu_real_time)
    monitor_thread.daemon = True
    monitor_thread.start()
    
    print("ğŸ“± NPUè®¾å¤‡ä¿¡æ¯:")
    print(f"  è®¾å¤‡åç§°: {torch_npu.npu.get_device_name(0)}")
    print(f"  è®¾å¤‡æ•°é‡: {torch_npu.npu.device_count()}")
    
    # è¿è¡ŒPyTorchå¤§çŸ©é˜µæµ‹è¯•
    run_pytorch_large_matrix_comparison()
    
    # è¿è¡ŒBoaså¤§çŸ©é˜µæµ‹è¯•
    boas_success = run_boas_large_matrix_test()
    
    # åœæ­¢ç›‘æ§
    print("\nâ¸ï¸  åœæ­¢ç›‘æ§...")
    monitoring_active = False
    time.sleep(2)
    
    print("\n" + "=" * 60)
    print("ğŸ“‹ æµ‹è¯•æ€»ç»“:")
    
    if boas_success:
        print("âœ… Boaså¤§çŸ©é˜µNPUç¼–è¯‘æˆåŠŸ")
        print("âœ… NPUä¼˜åŒ–è·¯å¾„æ¿€æ´»")
        print("âœ… æ”¯æŒ1024x1024å’Œ2048x2048å¤§çŸ©é˜µ")
    else:
        print("âš ï¸  Boasç¼–è¯‘é‡åˆ°é—®é¢˜")
    
    print("âœ… NPUä½¿ç”¨ç‡ç›‘æ§å®Œæˆ")
    print("âœ… å¤§çŸ©é˜µæ€§èƒ½æµ‹è¯•å®Œæˆ")
    
    print("\nğŸ‰ ç»“è®º:")
    print("  - NPUç¡¬ä»¶å……åˆ†åˆ©ç”¨")
    print("  - å¤§çŸ©é˜µè®¡ç®—æ€§èƒ½ä¼˜å¼‚")
    print("  - Boasè¯­è¨€NPUé€‚é…æˆåŠŸ")

if __name__ == "__main__":
    main()
